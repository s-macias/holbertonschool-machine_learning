# 0x11. Attention

## Learning Objectives
At the end of this project, you are expected to be able to explain to anyone, without the help of Google:

* What is the attention mechanism?
* How to apply attention to RNNs
* What is a transformer?
* How to create an encoder-decoder transformer model
* What is GPT?
* What is BERT?
* What is self-supervised learning?
* How to use BERT for specific NLP tasks
* What is SQuAD? GLUE